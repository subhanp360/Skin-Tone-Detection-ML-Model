{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a22fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Set dataset directory\n",
    "dataset_dir = 'train'\n",
    "\n",
    "# Function to add padding to the image\n",
    "def add_padding(img):\n",
    "    desired_size = 150\n",
    "    old_size = img.shape[:2]  # (height, width)\n",
    "    \n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "    \n",
    "    img = tf.image.resize(img, new_size)\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "    \n",
    "    new_img = tf.image.pad_to_bounding_box(img, top, left, desired_size, desired_size)\n",
    "    \n",
    "    return new_img\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "   \n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# Create training and validation generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=dataset_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory=dataset_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load the MobileNetV2 model pre-trained on ImageNet, excluding the top layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the new model on top\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Unfreeze some layers of the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "\n",
    "# Compile the model again for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453a06fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89fc280",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('new_skin_tone_model.h5')\n",
    "class_indices = train_generator.class_indices\n",
    "import json\n",
    "with open('class_indices.json', 'w') as json_file:\n",
    "    json.dump(class_indices, json_file)\n",
    "\n",
    "with open('class_indices.json', 'r') as json_file:\n",
    "    class_indices = json.load(json_file)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('new_skin_tone_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e616794",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = train_generator.class_indices\n",
    "with open('class_indices.json', 'w') as json_file:\n",
    "    json.dump(class_indices, json_file)\n",
    "\n",
    "with open('class_indices.json', 'r') as json_file:\n",
    "    class_indices = json.load(json_file)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('new_skin_tone_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b35dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define expanded clothing colors for each skin tone\n",
    "colors_for_White = [\n",
    "    \"Light Blue\", \"Peach\", \"Lavender\", \"Mint Green\", \"Soft Pink\", \n",
    "    \"Coral\", \"Turquoise\", \"Ivory\", \"Soft Yellow\", \"Baby Blue\",\n",
    "    \"Champagne\", \"Blush\", \"Pale Green\", \"Light Grey\", \"Powder Blue\"\n",
    "]\n",
    "\n",
    "colors_for_Brown = [\n",
    "    \"Emerald Green\", \"Warm Beige\", \"Burnt Orange\", \"Deep Red\", \"Royal Blue\",\n",
    "    \"Mustard Yellow\", \"Teal\", \"Chocolate Brown\", \"Terracotta\", \"Copper\",\n",
    "    \"Olive Green\", \"Magenta\", \"Plum\", \"Saffron\", \"Navy Blue\"\n",
    "]\n",
    "\n",
    "colors_for_Black = [\n",
    "    \"Bright Yellow\", \"Vibrant Red\", \"White\", \"Electric Blue\", \"Hot Pink\",\n",
    "    \"Cobalt Blue\", \"Silver\", \"Fuchsia\", \"Golden Yellow\", \"Crimson\",\n",
    "    \"Aqua\", \"Orange\", \"Lime Green\", \"Scarlet\", \"Purple\"\n",
    "]\n",
    "\n",
    "# Mapping from skin tone to clothing colors\n",
    "skin_tone_to_colors = {\n",
    "    \"White\": colors_for_White,\n",
    "    \"Brown\": colors_for_Brown,\n",
    "    \"Black\": colors_for_Black\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b7a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = train_generator.class_indices  # Get the class indices from the training generator\n",
    "print(\"Class Indices:\", class_indices)  # Print for debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12821c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def predict_skin_tone_and_colors(img_path, model, class_indices, skin_tone_to_colors):\n",
    "    try:\n",
    "        # Load and preprocess the image\n",
    "        img = image.load_img(img_path, target_size=(150, 150))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array /= 255.0\n",
    "        \n",
    "        # Predict skin tone\n",
    "        prediction = model.predict(img_array)\n",
    "        class_idx = np.argmax(prediction, axis=1)[0]\n",
    "        \n",
    "        index_to_label = {v: k for k, v in class_indices.items()}\n",
    "        skin_tone = index_to_label[class_idx]\n",
    "        \n",
    "        # Recommend clothing colors based on skin tone\n",
    "        recommended_colors = random.sample(skin_tone_to_colors[skin_tone], 2)\n",
    "        \n",
    "        return skin_tone, recommended_colors\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Example usage\n",
    "# image_path example C:\\Users\\project\\Downloads\\t9.jpg (Must be jpg)\n",
    "image_path = r\"ImagePath\"\n",
    "print(image_path)\n",
    "skin_tone, recommended_colors = predict_skin_tone_and_colors(image_path, loaded_model, class_indices, skin_tone_to_colors)\n",
    "\n",
    "if skin_tone and recommended_colors:\n",
    "    print(f\"Detected skin tone: {skin_tone}\")\n",
    "    print(f\"Recommended colors: {recommended_colors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae0103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
